{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \n",
    "    def __init__(self, ori_file_name):   \n",
    "        '''\n",
    "        ori_file_name:原始数据文件的文件名。(原始数据放在当前目录下即可)\n",
    "        '''\n",
    "        self.ori_file_name = ori_file_name\n",
    "        self.ori_df = pd.read_csv(ori_file_name).iloc[:,2:]   # 原始数据的df (去掉index和timestamp)\n",
    "        self.col_name = self.ori_df.columns.tolist()   # 完整粒子名\n",
    "        \n",
    "        \n",
    "    def get_ptc_name(self):  \n",
    "        '''\n",
    "        返回剥离多余符号后的粒子名，如：46Ti\n",
    "        '''\n",
    "        short_name = list(map(lambda x:x[1:-8], self.col_name))\n",
    "        return short_name\n",
    "    \n",
    "    \n",
    "    def get_cleaned_data(self):  \n",
    "        '''\n",
    "        清洗数据，将负值置为0, 并保存清洗后的数据\n",
    "        '''\n",
    "        cleaned_df = self.ori_df.copy()\n",
    "        cleaned_df[cleaned_df<=0]=np.nan   # 不大于0的区域全部置为nan\n",
    "        file_name = 'cleaned_'+ self.ori_file_name\n",
    "        cleaned_df.to_csv(file_name, index=None)\n",
    "        print('%s have been saved.' % file_name)\n",
    "        return cleaned_df\n",
    "    \n",
    "    \n",
    "    def get_basic_metirct(self, cleaned_df): \n",
    "        '''\n",
    "        得到 [去除符号后的粒子名，每种粒子出现的次数,最小强度，最大强度，平均强度，总强度，强度标准差] 的df；\n",
    "        并插入metirc列作为index；最后保存\n",
    "        cleaned_df：get_cleaned_data得到的清洗后数据的df\n",
    "        '''\n",
    "        basic_metric = pd.DataFrame()\n",
    "        short_name = pd.DataFrame(np.array(self.get_ptc_name()).reshape(1,-1), columns=self.col_name)   # 去除符号后的粒子名\n",
    "        count = cleaned_df[cleaned_df>0].count().to_frame().T     # 某种粒子出现次数\n",
    "        min_ints = cleaned_df.min().to_frame().T    # 某种粒子强度最小值\n",
    "        max_ints = cleaned_df.max().to_frame().T    # 某种粒子强度最大值\n",
    "        sum_ints = pd.DataFrame(np.nansum(cleaned_df, axis=0).reshape(1,-1), columns=self.col_name)    # 某种粒子强度和\n",
    "        avg_ints = pd.DataFrame(np.nanmean(cleaned_df, axis=0).reshape(1,-1), columns=self.col_name)   # 某种粒子强度平均\n",
    "        std_ints = pd.DataFrame(np.nanstd(cleaned_df, axis=0).reshape(1,-1), columns=self.col_name)    # 某种粒子强度的标准差\n",
    "        basic_metric = pd.concat([short_name, min_ints, max_ints, count, sum_ints, avg_ints, std_ints], axis=0) \n",
    "        basic_metric.insert(0, 'metric', value=['ptc_name', 'min_ints', 'max_ints', 'count','sum_ints','avg_ints', 'std_ints'])\n",
    "        basic_metric.set_index(['metric'],inplace=True)   # metric 列作为index\n",
    "        file_name = 'basic_metric_' + self.ori_file_name\n",
    "        basic_metric.to_csv(file_name)\n",
    "        print('%s have been saved.' % file_name)\n",
    "        return basic_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterMethod:\n",
    "\n",
    "    def __init__(self, data_df, metric_df):\n",
    "        '''\n",
    "        data_csv: 清洗后的df\n",
    "        metric_csv: 清洗后数据统计指标的df\n",
    "        '''\n",
    "        self.data_df = data_df\n",
    "        self.metric_df = metric_df\n",
    "        self.col_name = self.data_df.columns.tolist()\n",
    "\n",
    "        self.cur_df = self.data_df  # 每次要进行被迭代的df\n",
    "\n",
    "        self.iter_cnt = 0  # 迭代次数\n",
    "        self.all_thr = list()  # 每次迭代后得到的阈值\n",
    "\n",
    "    def get_avg(self):\n",
    "        '''\n",
    "        求出每种粒子强度的平均值，返回nparray\n",
    "        '''\n",
    "        return np.nanmean(self.cur_df, axis=0)\n",
    "\n",
    "    def get_std(self):\n",
    "        '''\n",
    "        求出每种粒子强度的标准差，返回nparray\n",
    "        '''\n",
    "        return np.nanstd(self.cur_df, axis=0)\n",
    "\n",
    "    def get_thr(self):\n",
    "        '''\n",
    "        求出每个csv文件的阈值,并更新self.iter_cnt, self.all_thr\n",
    "        '''\n",
    "        avg_tmp = self.get_avg()\n",
    "        std_tmp = self.get_std()\n",
    "        thr = np.nanmean(3 * std_tmp + avg_tmp)\n",
    "        self.all_thr.append(thr)\n",
    "        self.iter_cnt += 1\n",
    "        return thr\n",
    "\n",
    "    def gt_file(self, cnt):\n",
    "        '''\n",
    "        创建gt文件夹并返回对应迭代轮数的csv文件名\n",
    "        '''\n",
    "        dir_path = os.path.join(os.getcwd(), \"gt\")\n",
    "        flag = os.path.exists(dir_path)\n",
    "        if not flag:\n",
    "            os.makedirs(dir_path)\n",
    "        file_name = str(cnt) + \".csv\"\n",
    "        file_path = os.path.join(dir_path, file_name)\n",
    "        return file_path\n",
    "\n",
    "    def lt_file(self, cnt):\n",
    "        '''\n",
    "        创建lt文件夹并返回对应迭代轮数的csv文件名, 如：gt/1.csv\n",
    "        '''\n",
    "        dir_path = os.path.join(os.getcwd(), \"lt\")\n",
    "        flag = os.path.exists(dir_path)\n",
    "        if not flag:\n",
    "            os.makedirs(dir_path)\n",
    "        file_name = str(cnt) + \".csv\"\n",
    "        file_path = os.path.join(dir_path, file_name)\n",
    "        return file_path\n",
    "\n",
    "    def update_df(self, thr, cnt):\n",
    "        '''\n",
    "        根据阈值保存为两个csv文件：'gt/1.csv'、'lt/1.csv'；并返回小于阈值的df\n",
    "        '''\n",
    "        gt_df = self.cur_df[self.cur_df >= thr]\n",
    "        gt_df.to_csv(self.gt_file(cnt), index=None)\n",
    "        lt_df = self.cur_df[self.cur_df < thr]\n",
    "        lt_df.to_csv(self.lt_file(cnt), index=None)\n",
    "        print(\"The %s th iteration have been finished.\" % cnt)\n",
    "        return lt_df\n",
    "\n",
    "    def iterator(self):\n",
    "        '''\n",
    "        迭代过程\n",
    "        '''\n",
    "        beg_DF = self.cur_df\n",
    "        end_DF = self.cur_df\n",
    "        flag = False\n",
    "        while not flag:\n",
    "            beg_DF = end_DF\n",
    "            THR = self.get_thr()  # self.iter_cnt 在此处已+1\n",
    "            end_DF = self.update_df(THR, self.iter_cnt)\n",
    "            self.cur_df = end_DF\n",
    "            if beg_DF.equals(end_DF):\n",
    "                flag = True\n",
    "\n",
    "    def get_final_result(self, resolve_data):\n",
    "        '''\n",
    "        输入：溶解态的最终结果为 lt/last_iter_cnt.csv\n",
    "        结果：得到颗粒态的最终结果 gt/last_iter_cnt+1.csv\n",
    "        '''\n",
    "        resolve_df = pd.read_csv(resolve_data)\n",
    "        particle_df = self.data_df[pd.isnull(resolve_df)]\n",
    "        # pd.isnull(resolve_df_：溶解态df的非空位为False，空位为True，与清洗后的原始数据做mask\n",
    "        particle_df.to_csv(self.gt_file(self.iter_cnt + 1), index=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonMethod:\n",
    "\n",
    "    def __init__(self, data_df, metric_df, credible):\n",
    "        '''\n",
    "        data_df：清洗后数据的df\n",
    "        metric_df：清洗后数据统计指标的df\n",
    "        credible：置信度。小数表示，如0.997\n",
    "        '''\n",
    "        self.data_df = data_df\n",
    "        self.metric_df = metric_df\n",
    "        self.col_name = self.data_df.columns.tolist()\n",
    "        self.m = self.metric_df.iloc[5]  # 未归一化的强度均值，归一化处理后作为λ\n",
    "        self.credible = credible\n",
    "\n",
    "\n",
    "    def normal_lambda(self):\n",
    "        '''\n",
    "        将强度均值归一化，得到可用于泊松计算λ。\n",
    "        返回的df包括每种粒子的 [强度均值，λ，scale], 并保存该df，每行都是float。\n",
    "        '''\n",
    "        lamb_li = []  # 每种粒子归一化后的λ\n",
    "        scale_li = []  # 每种粒子的缩放系数scale\n",
    "        scale = 1.0\n",
    "        for val in self.m:\n",
    "            if val > 0 and val <= 1:\n",
    "                scale = 50.0\n",
    "            elif val > 1 and val <= 2:\n",
    "                scale = 25.0\n",
    "            elif val > 2 and val <= 3:\n",
    "                scale = 15.0\n",
    "            elif val > 3 and val <= 35:\n",
    "                scale = 1.0\n",
    "            else:\n",
    "                scale = 0.33\n",
    "            lamb_li.append(round(val * scale))\n",
    "            scale_li.append(scale)\n",
    "\n",
    "        lamb_li = np.array(lamb_li).reshape(1, -1)\n",
    "        scale_li = np.array(scale_li).reshape(1, -1)\n",
    "        res_arr = np.concatenate((lamb_li, scale_li), axis=0)\n",
    "        res_df = pd.DataFrame(res_arr, columns=self.col_name)\n",
    "        res_df = pd.concat([self.m.to_frame().T, res_df])\n",
    "        res_df.insert(0, 'metric', value=['avg_ints', 'lambda', 'scale'])\n",
    "        res_df.set_index(['metric'], inplace=True)  # metric 列作为index\n",
    "        file_name = \"poisson_normalize_lambda.csv\"\n",
    "        res_df.to_csv(file_name)\n",
    "        return res_df\n",
    "\n",
    "\n",
    "    def poisson(self, k, lamb):\n",
    "        '''\n",
    "        泊松方程，计算得到单词的概率值。在计算最终阈值时需要将概率累加\n",
    "        lamb：归一化后的λ,一定是整数\n",
    "        '''\n",
    "        kjie = 1  # k!\n",
    "        for i in range(1, k):\n",
    "            kjie *= i\n",
    "        lamb = float(lamb)\n",
    "        pk = np.power(lamb, k) / kjie * np.exp(-lamb)\n",
    "        return pk\n",
    "\n",
    "\n",
    "    def get_ints_thr(self):\n",
    "        '''\n",
    "        计算得到每种元素的阈值df，并保存\n",
    "        '''\n",
    "        lamb = self.normal_lambda().iloc[1].values.astype('int')\n",
    "        scale = self.normal_lambda().iloc[2].values\n",
    "        ints_val = []\n",
    "        for i in range(len(self.col_name)):\n",
    "            thr = 0.0\n",
    "            prob = 0.0\n",
    "            for k in range(1, 100):\n",
    "                prob += self.poisson(k, lamb[i])\n",
    "                if prob >= self.credible:\n",
    "                    thr = k / scale[i]\n",
    "                    break\n",
    "            ints_val.append(thr)\n",
    "        ints_val = pd.DataFrame(np.array(ints_val).reshape(1, -1), columns=self.col_name)\n",
    "        file_name = \"intensity_threshold.csv\"\n",
    "        ints_val.to_csv(file_name, index=None)\n",
    "        return ints_val\n",
    "\n",
    "\n",
    "    def classifier(self):\n",
    "        '''\n",
    "        根据每种元素强度的阈值区分颗粒态和溶解态粒子，分别保存为df\n",
    "        '''\n",
    "        resolve = pd.DataFrame()  # 分类后的溶解态粒子数据\n",
    "        particle = pd.DataFrame()  # 分类后的颗粒态粒子数据\n",
    "        ints_thr = self.get_ints_thr()\n",
    "        ints_thr_li = ints_thr.values[0]\n",
    "\n",
    "        for idx in range(len(self.col_name)):\n",
    "            single_ptc_df = self.data_df.iloc[:, idx].to_frame()\n",
    "            single_ptc_resolve = single_ptc_df[single_ptc_df >= ints_thr_li[idx]]\n",
    "            particle = pd.concat([particle, single_ptc_resolve], axis=1)\n",
    "\n",
    "        resolve = self.data_df[pd.isnull(particle)]\n",
    "        particle.to_csv(\"Poisson_particle.csv\", index=None)\n",
    "        print(\"Particle have been saved.\")\n",
    "        resolve.to_csv(\"Poisson_resolve.csv\", index=None)\n",
    "        print(\"Resolve have been saved.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcess:\n",
    "\n",
    "    def __init__(self, particle_csv, resolve_csv):\n",
    "        '''\n",
    "        particle_csv ：颗粒态数据csv文件名，放在当前目录下即可\n",
    "        resolve_csv：溶解态数据csv文件名，放在当前目录下即可\n",
    "        '''\n",
    "        self.ptc_df = pd.read_csv(particle_csv)\n",
    "        self.resl_df = pd.read_csv(resolve_csv)\n",
    "        self.df_len = len(self.resl_df)\n",
    "        self.col_name = self.ptc_df.columns\n",
    "\n",
    "\n",
    "    def get_background(self):\n",
    "        '''\n",
    "        计算每种粒子的背景值并保存为csv\n",
    "        '''\n",
    "        BG = pd.DataFrame([np.nanmean(self.resl_df, axis=0)] * self.df_len, columns=self.col_name)\n",
    "        return BG\n",
    "\n",
    "\n",
    "    def substract_background(self):\n",
    "        '''\n",
    "        对颗粒态数据减去背景值并保存为csv\n",
    "        background_df：背景值df\n",
    "        '''\n",
    "        BG = self.get_background()\n",
    "        file_name = 'substract_bg_particle.csv'\n",
    "        substract_bg_particle = self.ptc_df - BG\n",
    "        substract_bg_particle.to_csv(file_name, index=None)\n",
    "        print(\"%s have been saved.\" % file_name)\n",
    "\n",
    "\n",
    "    def select_columns(self, final_particle_csv, target_particle):\n",
    "        '''\n",
    "        在减去背景的颗粒态数据中选择要处理的粒子，组成df并保存为csv\n",
    "        final_particle_csv：减去背景后的颗粒态csv文件名，放在该目录下即可\n",
    "        target_particle：要选择的粒子名，如:'Au'\n",
    "        '''\n",
    "        ptc_df = pd.read_csv(final_particle_csv)\n",
    "        ptc_name_full_li = ptc_df.columns.tolist()  # 表头\n",
    "        ptc_name_short_li = list(map(lambda x: x[-10:-8], ptc_name_full_li))  # 元素名\n",
    "        select_col_li = []  # 选中元素所在列的完整列名\n",
    "\n",
    "        for i in range(len(ptc_name_full_li)):\n",
    "            if target_particle == ptc_name_short_li[i]:\n",
    "                select_col_li.append(ptc_name_full_li[i])\n",
    "\n",
    "        selected_ptc_df = pd.DataFrame(ptc_df, columns=select_col_li)\n",
    "        file_name = target_particle + '_in_' + final_particle_csv\n",
    "        selected_ptc_df.to_csv(file_name, index=None)\n",
    "        print(\"%s particle have been selected.\" % target_particle)\n",
    "\n",
    "\n",
    "    def get_particle_number_concentration(self, selected_particle_csv, TE, speed, CPS):\n",
    "        '''\n",
    "        ！！旧的颗粒数浓度计算方法！！\n",
    "\n",
    "        计算去除背景后颗粒态的目标元素的颗粒数浓度。\n",
    "        selected_particle_csv：减去背景后的颗粒态目标元素的csv文件名，放在该目录下即可\n",
    "        TE：计算参数，手动输入\n",
    "        speed：流速，手动输入\n",
    "        CPS：目标粒子的单位CPS，手动输入\n",
    "        '''\n",
    "        ele_name = selected_particle_csv[0:2]\n",
    "        selected_ptc_df = pd.read_csv(selected_particle_csv)\n",
    "        ints_sum = pd.DataFrame(np.nansum(selected_ptc_df, axis=0).reshape(1, -1), columns=selected_ptc_df.columns)\n",
    "        coef = 1000 / (2.5 * TE * speed * CPS)  # 强度和df要乘的系数\n",
    "        ptc_num_concentration = coef * ints_sum\n",
    "        file_name = ele_name + \"_particle_number_concentration.csv\"\n",
    "        ptc_num_concentration.to_csv(file_name, index=None)\n",
    "        print(\"The particle number concentration of %s have been computed.\" % ele_name)\n",
    "\n",
    "\n",
    "    def get_TE(self, selected_particle_csv):\n",
    "        '''\n",
    "        利用Std文件减去背景值后的目标粒子数据，计算得到TE，并保存对应csv。\n",
    "        selected_particle_csv：减去背景后的颗粒态目标元素的csv文件名，放在该目录下即可\n",
    "        '''\n",
    "        std_df = pd.read_csv(selected_particle_csv)  # std文件的df\n",
    "        TE = pd.DataFrame((std_df.count()) / (2.5 * 0.02 * 1e6), columns=std_df.columns)\n",
    "        TE.to_csv(\"TE.csv\", index=None)\n",
    "        print(\"TE have been computed.\")\n",
    "\n",
    "\n",
    "    def get_particle_number_con_new(self, selected_particle_csv, TE, speed):\n",
    "        '''\n",
    "        ！！新的的颗粒数浓度计算方法！！\n",
    "\n",
    "        计算去除背景后颗粒态的目标元素的颗粒数浓度。\n",
    "        selected_particle_csv：减去背景后的颗粒态目标元素的csv文件名，放在该目录下即可\n",
    "        TE：计算参数，手动输入\n",
    "        speed：流速，手动输入\n",
    "        '''\n",
    "        ele_name = selected_particle_csv[0:2]\n",
    "        selected_ptc_df = pd.read_csv(selected_particle_csv)\n",
    "        ptc_cnt = selected_ptc_df.count()\n",
    "        coef = 1 / (2.5 * TE * speed)  # 粒子计数要乘的系数\n",
    "        res = coef * ptc_cnt\n",
    "        ptc_num_con = pd.DataFrame(res, columns=selected_ptc_df.columns)\n",
    "        file_name = ele_name + \"_particle_number_concentration.csv\"\n",
    "        ptc_num_con.to_csv(file_name, index=None)\n",
    "        print(\"The particle number concentration of %s have been computed.\" % ele_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 泊松法执行完整流程\n",
    "def main():\n",
    "    if TE_flag:  # 计算TE\n",
    "        #  一：执行\n",
    "        data_loader = DataLoader(origin_csv)                        # 实例化\n",
    "        cleaned_data = data_loader.get_cleaned_data()               # 得到清洗后的数据\n",
    "        metric_data = data_loader.get_basic_metirct(cleaned_data)   # 得到相关指标统计结果\n",
    "\n",
    "        # 二：Poisson执行\n",
    "        poissonmethod = PoissonMethod(cleaned_data, metric_data, credible)   # 实例化\n",
    "        avgints_lambda_scale = poissonmethod.normal_lambda()                 # 得到与lambda相关参数组成的csv\n",
    "        intensity_threshold = poissonmethod.get_ints_thr()                   # 经过泊松过程得到强度阈值的csv\n",
    "        poissonmethod.classifier()                                           # 分类得到颗粒态和溶解态数据csv\n",
    "\n",
    "        # 三：执行\n",
    "        p_process = PostProcess('Poisson_particle.csv', 'Poisson_resolve.csv')    # 实例化\n",
    "        p_process.substract_background()                                          # 颗粒态数据减背景\n",
    "        p_process.select_columns('substract_bg_particle.csv', 'Au')               # 在减背景后的颗粒态数据选择Au\n",
    "        p_process.get_TE('Au_in_substract_bg_particle.csv')                       # 计算TE\n",
    "\n",
    "        \n",
    "    else:   # 计算颗粒数浓度\n",
    "        #  一：执行\n",
    "        data_loader = DataLoader(origin_csv)                        # 实例化\n",
    "        cleaned_data = data_loader.get_cleaned_data()               # 得到清洗后的数据\n",
    "        metric_data = data_loader.get_basic_metirct(cleaned_data)   # 得到相关指标统计结果\n",
    "\n",
    "        # 二：Poisson执行\n",
    "        poissonmethod = PoissonMethod(cleaned_data, metric_data, credible)  # 实例化\n",
    "        avgints_lambda_scale = poissonmethod.normal_lambda()                # 得到与lambda相关参数组成的csv\n",
    "        intensity_threshold = poissonmethod.get_ints_thr()                  # 经过泊松过程得到强度阈值的csv\n",
    "        poissonmethod.classifier()                                          # 分类得到颗粒态和溶解态数据csv\n",
    "\n",
    "        # 三：执行\n",
    "        p_process = PostProcess('Poisson_particle.csv', 'Poisson_resolve.csv')                    # 实例化\n",
    "        p_process.substract_background()                                                          # 颗粒态数据减背景\n",
    "        p_process.select_columns('substract_bg_particle.csv', 'Au')                               # 在减背景后的颗粒态数据选择Au\n",
    "        p_process.get_particle_number_con_new('Au_in_substract_bg_particle.csv', TE, speed)       # 计算Au的颗粒数浓度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_li = ['64nmAu-TE.csv', '5X.csv', '10X.csv', '100X .csv', '1000X.csv', '50nm.csv', '50nm-P.csv']    # 文件列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_5X.csv have been saved.\n",
      "basic_metric_5X.csv have been saved.\n",
      "Particle have been saved.\n",
      "Resolve have been saved.\n",
      "substract_bg_particle.csv have been saved.\n",
      "Au particle have been selected.\n",
      "The particle number concentration of Au have been computed.\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "origin_csv =  file_li[1]    # 原始数据的csv文件\n",
    "credible = 1e-7             # 泊松分布的置信度\n",
    "\n",
    "TE_flag = False             # 是否计算TE\n",
    "\n",
    "speed = 0.02                # 流速\n",
    "TE = 0.67544                # TE      \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传统方法执行流程\n",
    "file_li = ['64nmAu-TE.csv', '5X.csv', '10X.csv', '100X.csv', '1000X.csv', '50nm.csv', '50nm-P.csv']    # 文件列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50nm-P.csv\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "origin_csv =  file_li[6]    # 原始数据的csv文件\n",
    "print(origin_csv)\n",
    "\n",
    "TE_flag = False             # 是否计算TE\n",
    "\n",
    "speed = 0.02                # 流速\n",
    "TE = 0.36726                # TE      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_50nm-P.csv have been saved.\n",
      "basic_metric_50nm-P.csv have been saved.\n",
      "The 1 th iteration have been finished.\n",
      "The 2 th iteration have been finished.\n",
      "The 3 th iteration have been finished.\n",
      "The 4 th iteration have been finished.\n",
      "The 5 th iteration have been finished.\n",
      "The 6 th iteration have been finished.\n",
      "The 7 th iteration have been finished.\n",
      "The 8 th iteration have been finished.\n",
      "The 9 th iteration have been finished.\n",
      "The 10 th iteration have been finished.\n",
      "The 11 th iteration have been finished.\n",
      "The 12 th iteration have been finished.\n",
      "The 13 th iteration have been finished.\n"
     ]
    }
   ],
   "source": [
    "# 执行流程\n",
    "#  一：数据清洗执行\n",
    "data_loader = DataLoader(origin_csv)                        # 实例化\n",
    "cleaned_data = data_loader.get_cleaned_data()               # 得到清洗后的数据\n",
    "metric_data = data_loader.get_basic_metirct(cleaned_data)   # 得到相关指标统计结果\n",
    "\n",
    "# 二：迭代法执行\n",
    "itermethod = IterMethod(cleaned_data, metric_data)             # 实例化\n",
    "itermethod.iterator()                                          # 迭代过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "itermethod.get_final_result('lt/13.csv')                       # 得到最终的颗粒态数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substract_bg_particle.csv have been saved.\n",
      "Au particle have been selected.\n",
      "The particle number concentration of Au have been computed.\n"
     ]
    }
   ],
   "source": [
    "# 三：后处理执行\n",
    "p_process = PostProcess('14.csv', '13.csv')                                               # 实例化\n",
    "p_process.substract_background()                                                          # 颗粒态数据减背景\n",
    "p_process.select_columns('substract_bg_particle.csv', 'Au')                               # 在减背景后的颗粒态数据选择Au\n",
    "# p_process.get_TE('Au_in_substract_bg_particle.csv')                                       # 计算TE\n",
    "p_process.get_particle_number_con_new('Au_in_substract_bg_particle.csv', TE, speed)       # 计算Au的颗粒数浓度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'projection'",
   "language": "python",
   "name": "projection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
