{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工作说明\n",
    "\n",
    "#### 一、单位强度文件在处理前都要：\n",
    "* 1.将其中的空值列删掉\n",
    "* 2.按照不同的日期将单位强度分开保存\n",
    "* 3.删去除单位强度外的列(比如表示日期的首列)\n",
    "* 4.并将文件名改为英文(如：'23.csv')，并保存为csv\n",
    "\n",
    "\n",
    "#### 二、每个样本对质量处理后的数据结构：\n",
    "\n",
    "<img src='./Reference/form_of_mass_processed.png' width='660px'>\n",
    "\n",
    "\n",
    "#### 三、代码操作说明：\n",
    "\n",
    "* 以日期23的文件夹为例\n",
    "* p = PreProcess(base, file, drop, percent_thr, top_k)：实例化一个处理器对象\n",
    "* P.select_elements()：执行 **[ 空行舍弃;元素列舍弃;元素质量计算;元素质量占比计算;主要元素字典及个数统计;top K含量元素统计;文件名拼接 ]** 功能，并生成一个csv文件。\n",
    "\n",
    "\n",
    "**执行过程**\n",
    "```\n",
    "file_list = [ 'S15_Poisson_particle.csv',\n",
    "             'S16_Poisson_particle.csv',\n",
    "             'S25_Poisson_particle.csv',\n",
    "             'S27_Poisson_particle.csv',\n",
    "             'S35_Poisson_particle.csv']\n",
    "\n",
    "base = '23_base.csv'\n",
    "\n",
    "drop = ['[42Ca]+ (cts)','[44Ca]+ (cts)','[56Fe]+ (cts)',]\n",
    "\n",
    "percent_thr = 0.1\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "for file in file_list:\n",
    "    P = PreProcess(base, file, drop, percent_thr, top_k)\n",
    "    P.select_elements()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess:   # 数据集的预处理\n",
    "    \n",
    "    def __init__(self, unit_intensity, ptc_intensity, drop_ptc, percent_thr, top_k):\n",
    "        '''\n",
    "        base:单位强度csv文件名\n",
    "        ptc_intensity:要处理的颗粒态强度csv文件名\n",
    "        drop_ptc:要丢弃的粒子名组成的列表，如：['[56Fe]+ (cts)']\n",
    "        percent_thr:字典要统计的元素占比的阈值，如0.1\n",
    "        top_k:要统计的含量前k的k值，如10\n",
    "        '''\n",
    "        self.base = unit_intensity\n",
    "        self.target = ptc_intensity\n",
    "        self.drop_ptc = drop_ptc\n",
    "        self.percent_thr = percent_thr\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        \n",
    "        \n",
    "    def read_base(self):\n",
    "        '''\n",
    "        读取单位强度的csv文件并将其数据转换为float型\n",
    "        返回单位强度处理后的df\n",
    "        '''\n",
    "        return pd.read_csv(self.base).astype(\"float\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    def drop_particle(self):\n",
    "        '''\n",
    "        读取颗粒态强度的csv文件并将将不处理的粒子列去掉,之后将其中全NaN的行删掉\n",
    "        返回颗粒态强度处理后的df\n",
    "        '''\n",
    "        ptc_ints = pd.read_csv(self.target)\n",
    "        for item in self.drop_ptc:\n",
    "            ptc_ints = ptc_ints.drop(item, axis=1)\n",
    "        ptc_ints = ptc_ints.dropna(axis=0,how='all')\n",
    "        return ptc_ints\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_mass_filename(self):\n",
    "        '''\n",
    "        从颗粒态强度文件名中读取样品标签(如：S15)\n",
    "        返回颗粒态质量csv文件的文件名(如：'S15_mass.csv')\n",
    "        '''\n",
    "        label = self.target[0:-21]\n",
    "        suffix = '_mass_final.csv'\n",
    "        return label+suffix\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_particle_mass(self):\n",
    "        '''\n",
    "        计算颗粒态质量并返回相应df\n",
    "        '''\n",
    "        mass_df = self.drop_particle() / self.read_base().values\n",
    "        return mass_df\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_mass_sum(self):\n",
    "        '''\n",
    "        计算每个颗粒质量和并返回相应df\n",
    "        '''\n",
    "        def sum_mass(row):\n",
    "            return np.nansum(row)\n",
    "        \n",
    "        mass_df = self.get_particle_mass()\n",
    "        total_mass = mass_df.apply(lambda x:sum_mass(x), axis=1)\n",
    "        total_mass = total_mass.values\n",
    "        mass_df.insert(mass_df.shape[1], 'total_mass', total_mass)\n",
    "        return mass_df\n",
    "        \n",
    "    \n",
    "    \n",
    "    def get_short_ele_name(self):\n",
    "        '''\n",
    "        计算每个颗粒质量和并返回响应df\n",
    "        '''\n",
    "        col = self.drop_particle().columns\n",
    "        new_col = []\n",
    "        for item in col:\n",
    "            new_col.append(item[1:-8])\n",
    "        return new_col\n",
    "    \n",
    "    \n",
    "    \n",
    "    def normalize_mass(self):\n",
    "        '''\n",
    "        对每种元素质量进行归一化，并拼接df,返回相应df\n",
    "        '''\n",
    "        mass_df = self.get_mass_sum()\n",
    "        ptc_mass = mass_df.iloc[:,0:-1]\n",
    "        total_mass = self.get_mass_sum().iloc[:,-1]\n",
    "        \n",
    "        def divide(col, total):   # 将一列数据除以总质量\n",
    "            return col/total\n",
    "\n",
    "        ptc_percent = ptc_mass.apply(lambda x:divide(x,total_mass), axis=0)\n",
    "        ptc_percent.columns = self.get_short_ele_name()\n",
    "        normed_ptc = pd.concat([mass_df,ptc_percent], axis=1)\n",
    "        normed_ptc.reset_index(inplace=True, drop=True) \n",
    "        return normed_ptc\n",
    "    \n",
    "    \n",
    "    \n",
    "    def select_elements(self):\n",
    "        '''\n",
    "        将占比>0.1的元素保存为字典，并记录符合条件的元素个数；\n",
    "        将占比前k的元素保存为字典；\n",
    "        拼接df，保存为csv文件\n",
    "        '''\n",
    "        main_ele_dict = []\n",
    "        main_ele_len = []\n",
    "        \n",
    "        topk_dict = []\n",
    "        \n",
    "        normed_df = self.normalize_mass()\n",
    "        col_len = normed_df.shape[1]\n",
    "        percent = normed_df.iloc[:, (col_len+1)//2:]\n",
    "\n",
    "        \n",
    "        def process_row(row):\n",
    "            # 对每行进行处理，每行数据为Series。\n",
    "            row = row.sort_values(ascending=False)\n",
    "            \n",
    "            # 含量大于阈值的元素记录：对每行数据先按照占比排序，之后记录为字典以及元素个数\n",
    "            ele_dict = {}\n",
    "            ele_leng = 0\n",
    "            ele_leng = len(row[row>self.percent_thr])\n",
    "            for i in range(ele_leng):\n",
    "                ele_dict[row.index[i]] = row[i]\n",
    "            main_ele_dict.append(ele_dict)\n",
    "            main_ele_len.append(ele_leng)\n",
    "            \n",
    "            # top K 含量元素记录：对每行数据先按照占比排序，之后记录为字典\n",
    "            top_d = {}\n",
    "            top_leng = row.shape[0]\n",
    "            for i in range(top_leng):\n",
    "                if top_leng == self.top_k:\n",
    "                    break\n",
    "                top_d[row.index[i]] = row[i]\n",
    "            topk_dict.append(top_d)\n",
    "            \n",
    "\n",
    "            \n",
    "        percent.apply(lambda x:process_row(x), axis=1)\n",
    "        \n",
    "        main_ele_dict = pd.DataFrame(pd.Series(main_ele_dict), columns=['components'])\n",
    "        main_ele_len = pd.DataFrame(main_ele_len, columns=['number_of_components'])\n",
    "        topk_dict = pd.DataFrame(pd.Series(topk_dict), columns=['top_k'])\n",
    "        file_name = self.get_mass_filename()\n",
    "        vital_ele = pd.concat([main_ele_dict,main_ele_len,topk_dict], axis=1)\n",
    "        final_df = pd.concat([normed_df,vital_ele], axis=1)\n",
    "        final_df.to_csv(file_name, index=None)\n",
    "        print(\"%s have finished.\" % file_name)\n",
    "        \n",
    "        \n",
    "# file_name = self.get_mass_filename()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S15_mass_final.csv have finished.\n",
      "S16_mass_final.csv have finished.\n",
      "S25_mass_final.csv have finished.\n",
      "S27_mass_final.csv have finished.\n",
      "S35_mass_final.csv have finished.\n"
     ]
    }
   ],
   "source": [
    "# 23\n",
    "file_list = [ 'S15_Poisson_particle.csv',\n",
    "             'S16_Poisson_particle.csv',\n",
    "             'S25_Poisson_particle.csv',\n",
    "             'S27_Poisson_particle.csv',\n",
    "             'S35_Poisson_particle.csv']\n",
    "\n",
    "base = '23_base.csv'\n",
    "\n",
    "drop = ['[42Ca]+ (cts)','[44Ca]+ (cts)','[56Fe]+ (cts)',]\n",
    "\n",
    "percent_thr = 0.1\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "for file in file_list:\n",
    "    P = PreProcess(base, file, drop, percent_thr, top_k)\n",
    "    P.select_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S43_mass_final.csv have finished.\n",
      "S44_mass_final.csv have finished.\n",
      "S45_mass_final.csv have finished.\n",
      "S46_mass_final.csv have finished.\n",
      "S47_mass_final.csv have finished.\n",
      "S48_mass_final.csv have finished.\n",
      "S52_mass_final.csv have finished.\n",
      "S57_mass_final.csv have finished.\n",
      "S58_mass_final.csv have finished.\n"
     ]
    }
   ],
   "source": [
    "# 24\n",
    "file_list = [ 'S43_Poisson_particle.csv',\n",
    "             'S44_Poisson_particle.csv',\n",
    "             'S45_Poisson_particle.csv',\n",
    "             'S46_Poisson_particle.csv',\n",
    "             'S47_Poisson_particle.csv',\n",
    "             'S48_Poisson_particle.csv',\n",
    "             'S52_Poisson_particle.csv',\n",
    "             'S57_Poisson_particle.csv',\n",
    "             'S58_Poisson_particle.csv']\n",
    "\n",
    "base = '24_base.csv'\n",
    "\n",
    "drop = ['[42Ca]+ (cts)','[44Ca]+ (cts)','[56Fe]+ (cts)',]\n",
    "\n",
    "percent_thr = 0.1\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "for file in file_list:\n",
    "    P = PreProcess(base, file, drop, percent_thr, top_k)\n",
    "    P.select_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S73_mass_final.csv have finished.\n",
      "S75_mass_final.csv have finished.\n",
      "S79_mass_final.csv have finished.\n",
      "S83_mass_final.csv have finished.\n",
      "S84_mass_final.csv have finished.\n"
     ]
    }
   ],
   "source": [
    "# 25\n",
    "file_list = ['S73_Poisson_particle.csv',\n",
    "            'S75_Poisson_particle.csv',\n",
    "            'S79_Poisson_particle.csv',\n",
    "            'S83_Poisson_particle.csv',\n",
    "            'S84_Poisson_particle.csv']\n",
    "\n",
    "base = '25_base.csv'\n",
    "\n",
    "drop = ['[42Ca]+ (cts)','[44Ca]+ (cts)','[56Fe]+ (cts)',]\n",
    "\n",
    "percent_thr = 0.1\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "for file in file_list:\n",
    "    P = PreProcess(base, file, drop, percent_thr, top_k)\n",
    "    P.select_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S115_mass_final.csv have finished.\n"
     ]
    }
   ],
   "source": [
    "# 26\n",
    "file_list = ['S115_Poisson_particle.csv']\n",
    "\n",
    "base = '26_base.csv'\n",
    "\n",
    "drop = ['[42Ca]+ (cts)','[44Ca]+ (cts)','[56Fe]+ (cts)',]\n",
    "\n",
    "percent_thr = 0.1\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "for file in file_list:\n",
    "    P = PreProcess(base, file, drop, percent_thr, top_k)\n",
    "    P.select_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S143_mass_final.csv have finished.\n",
      "S145_mass_final.csv have finished.\n",
      "S156_mass_final.csv have finished.\n",
      "S157_mass_final.csv have finished.\n"
     ]
    }
   ],
   "source": [
    "# 27\n",
    "file_list = ['S143_Poisson_particle.csv',\n",
    "            'S145_Poisson_particle.csv',\n",
    "            'S156_Poisson_particle.csv',\n",
    "            'S157_Poisson_particle.csv']\n",
    "\n",
    "base = '27_base.csv'\n",
    "\n",
    "drop = ['[42Ca]+ (cts)','[44Ca]+ (cts)','[56Fe]+ (cts)',]\n",
    "\n",
    "percent_thr = 0.1\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "for file in file_list:\n",
    "    P = PreProcess(base, file, drop, percent_thr, top_k)\n",
    "    P.select_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'projection'",
   "language": "python",
   "name": "projection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
